import streamlit as st
import folium
from streamlit_folium import st_folium
import pandas as pd
import geopandas as gpd
from folium.plugins import HeatMap, MarkerCluster
import plotly.express as px
import numpy as np
from scipy.spatial import cKDTree, KDTree
import requests
import os
import time

try:
    from pyproj import Transformer
except ImportError:
    st.error("pyproj library not found. Please install it.")

# --- Configuration ---
API_KEY = "4e7a4a4d70646b73343261564e4c67"
SEOUL_API_BASE = f"http://openapi.seoul.go.kr:8088/{API_KEY}/json"

st.set_page_config(page_title="ì„œìš¸ì‹œ ì£¼ê±° ê°€ì¹˜ ë¶„ì„ (Pro)", page_icon="ğŸ™ï¸", layout="wide")

# --- 1. Data Ingestion & Caching ---

def fetch_and_cache_api(service, save_name):
    """Fetches data with pagination and caches to CSV. Handles large datasets."""
    if not os.path.exists('data'): os.makedirs('data')
    path = f"data/{save_name}.csv"
    
    # Cache Hit
    if os.path.exists(path):
        try: return pd.read_csv(path)
        except: pass
    
    # Cache Miss: Fetch from API
    all_rows = []
    start = 1
    step = 1000
    try:
        while True:
            end = start + step - 1
            url = f"{SEOUL_API_BASE}/{service}/{start}/{end}/"
            resp = requests.get(url, timeout=10)
            data = resp.json()
            
            if service in data and 'row' in data[service]:
                rows = data[service]['row']
                all_rows.extend(rows)
                if len(rows) < step: break
                start += step
                time.sleep(0.05)
            else:
                break
    except Exception as e:
        print(f"Fetch Error ({service}): {e}")
        return pd.DataFrame()
    
    df = pd.DataFrame(all_rows)
    if not df.empty: df.to_csv(path, index=False)
    return df

def get_real_data():
    """Aggregates all 10+ categories from Seoul Open Data."""
    data_list = []
    try: transformer = Transformer.from_crs("EPSG:2097", "EPSG:4326", always_xy=True)
    except: transformer = None

    with st.spinner("ğŸ“¦ ì„œìš¸ì‹œ ê³µê³µë°ì´í„° í†µí•© ë¡œë”© ì¤‘... (ìºì‹± ìµœì í™” ì ìš©)"):
        # Helper to process frame
        def process_frame(df, type_name, subtype, lat_keys, lon_keys, xy_keys=None, weight=1.0):
            if df.empty: return
            for _, r in df.iterrows():
                try:
                    lat, lon = None, None
                    # Try WGS84 first
                    for k in lat_keys:
                        if k in r and pd.notna(r[k]): lat = float(r[k]); break
                    for k in lon_keys:
                        if k in r and pd.notna(r[k]): lon = float(r[k]); break
                    
                    # Try GRS80 projection if missing
                    if (lat is None or lon is None) and xy_keys and transformer:
                        x = float(r.get(xy_keys[0]))
                        y = float(r.get(xy_keys[1]))
                        lon, lat = transformer.transform(x, y)
                    
                    if lat and lon:
                        name = r.get('NAME') or r.get('NAMES') or r.get('NM') or r.get('DUTYNAME') or r.get('M_NAME') or subtype
                        data_list.append({
                            'name': str(name),
                            'type': type_name,
                            'subtype': subtype,
                            'lat': lat, 'lon': lon,
                            'weight_factor': weight
                        })
                except: pass

        # 1. Safety & Smart
        process_frame(fetch_and_cache_api("SeoulPoliceStationWGS", "police"), 'safety', 'police', ['LAT'], ['LON'], weight=1.5)
        process_frame(fetch_and_cache_api("tbsSvcCctv", "cctv"), 'safety', 'cctv', ['LATITUDE','LAT'], ['LONGITUDE','LON'])
        process_frame(fetch_and_cache_api("SeoulSmartPole", "smartpole"), 'smart', 'smartpole', ['LAT'], ['LON'])

        # 2. Medical
        process_frame(fetch_and_cache_api("SeoulPharmacyStatusInfo", "pharmacy"), 'medical', 'pharmacy', ['WGS84_LAT'], ['WGS84_LON'])
        process_frame(fetch_and_cache_api("SeoulHospitalStatusInfo", "hospital"), 'medical', 'hospital', ['WGS84_LAT'], ['WGS84_LON'])

        # 3. Life & Admin
        process_frame(fetch_and_cache_api("SeoulWomensSafeDelivery", "delivery"), 'life', 'delivery', [], [], xy_keys=['X_COORD','Y_COORD']) # GRS80 fallback
        process_frame(fetch_and_cache_api("SeoulTraditionalMarket", "market"), 'life', 'market', ['GPS_LAT','LAT'], ['GPS_LET','LNG'])
        process_frame(fetch_and_cache_api("SeoulUminun", "uminun"), 'admin', 'kiosk', ['LAT'], ['LON'], xy_keys=['X_COORD','Y_COORD'])

        # 4. Mobility & Healing
        process_frame(fetch_and_cache_api("SeoulPublicBikeStationStatus", "bike"), 'mobility', 'bike', ['LAT','STATION_LAT'], ['LON','STATION_LNG'])
        process_frame(fetch_and_cache_api("SeoulForestPark", "park"), 'healing', 'park', ['LATITUDE','X_COORD'], ['LONGITUDE','Y_COORD'], xy_keys=['X_COORD','Y_COORD'])

    if not data_list: return pd.DataFrame()
    return pd.DataFrame(data_list)

def generate_mock_estate_data(n_samples=200):
    # Mock Estate Data with realistic Seoul rents (Shinlim area)
    lat_offsets = np.random.normal(0, 0.005, n_samples)
    lon_offsets = np.random.normal(0, 0.005, n_samples)
    lats = 37.4842 + lat_offsets
    lons = 126.9297 + lon_offsets
    # Rent per 3.3m2 (approx 5~15 man-won is realistic for cheap, 20+ for expensive)
    rent_per_pyeong = np.random.uniform(4, 18, n_samples) 
    return pd.DataFrame({
        'lat': lats, 'lon': lons, 
        'rent_per_area': rent_per_pyeong, 
        'name': [f"ë§¤ë¬¼_{i:03d}" for i in range(n_samples)]
    })

def preprocess_data(use_mock=False):
    # Base categories (Cafe, Gym, Conv) - keeping mock for base infrastructure as requested "Focus on Public API expansion"
    base_mock_list = []
    for _ in range(300):
        base_mock_list.append({
            'name':'Store', 
            'type':np.random.choice(['cafe','gym','convenience']), 
            'lat':37.4842+np.random.normal(0,0.005), 
            'lon':126.9297+np.random.normal(0,0.005),
            'weight_factor':1.0
        })
    base_df = pd.DataFrame(base_mock_list)

    if not use_mock:
        real_df = get_real_data()
        if not real_df.empty:
            final_df = pd.concat([base_df, real_df], ignore_index=True)
            return gpd.GeoDataFrame(final_df, geometry=gpd.points_from_xy(final_df.lon, final_df.lat), crs="EPSG:4326")
    
    return gpd.GeoDataFrame(base_df, geometry=gpd.points_from_xy(base_df.lon, base_df.lat), crs="EPSG:4326")

# --- 2. Algorithm ---
def calculate_seulsekwon_index(gdf, grid_res=30, max_dist=1000):
    gdf_proj = gdf.to_crs(epsg=32652)
    minx, miny, maxx, maxy = gdf_proj.total_bounds
    buffer = max_dist
    x_rng = np.arange(minx-buffer, maxx+buffer, grid_res)
    y_rng = np.arange(miny-buffer, maxy+buffer, grid_res)
    xx, yy = np.meshgrid(x_rng, y_rng)
    grid_points = np.c_[xx.ravel(), yy.ravel()]
    
    categories = ['cafe', 'gym', 'convenience', 'safety', 'medical', 'life', 'mobility', 'smart', 'admin', 'healing']
    score_dict = {}
    
    for cat in categories:
        subset = gdf_proj[gdf_proj['type'] == cat]
        scores = np.zeros(len(grid_points))
        if not subset.empty:
            coords = np.array(list(zip(subset.geometry.x, subset.geometry.y)))
            tree = KDTree(coords)
            chunk = 10000
            for i in range(0, len(grid_points), chunk):
                pts = grid_points[i:i+chunk]
                dists, idxs = tree.query(pts, k=1)
                
                valid_mask = dists < max_dist
                local_sc = np.zeros(len(dists))
                close = dists <= 100
                mid = (dists > 100) & (dists < max_dist)
                
                local_sc[close] = 10
                if np.any(mid):
                    local_sc[mid] = 10 - 9 * ((dists[mid]-100)/(max_dist-100))
                
                w_factors = subset.iloc[idxs]['weight_factor'].values
                scores[i:i+chunk] = local_sc * w_factors
                
        score_dict[f'score_{cat}'] = scores

    res_df = pd.DataFrame(grid_points, columns=['x','y'])
    for k, v in score_dict.items(): res_df[k] = v
    
    gdf_grid = gpd.GeoDataFrame(res_df, geometry=gpd.points_from_xy(res_df.x, res_df.y), crs="EPSG:32652")
    return gdf_grid.to_crs(epsg=4326)

# --- 3. Dashboard UI ---
st.markdown("## ğŸ™ï¸ í”„ë¦¬ë¯¸ì—„ ìŠ¬ì„¸ê¶Œ ë¶„ì„ & ì¶”ì²œ ì„œë¹„ìŠ¤")
st.markdown("**(ì„œìš¸ì‹œ ê³µê³µ ì¸í”„ë¼ ê¸°ë°˜ ì§€ëŠ¥í˜• ì£¼ê±° ê°€ì¹˜ ë¶„ì„)**")

# Sidebar
st.sidebar.header("âš–ï¸ ë¼ì´í”„ìŠ¤íƒ€ì¼ ê°€ì¤‘ì¹˜ (Weights)")
st.sidebar.caption("ì¤‘ìš”ë„ë¥¼ ì„ íƒí•˜ë©´ **100ì  ë§Œì **ìœ¼ë¡œ ì ìˆ˜ê°€ í™˜ì‚°ë©ë‹ˆë‹¤.")

w_opts = {'ê´€ì‹¬ ì—†ìŒ (0)':0.0, 'ë³´í†µ (1)':1.0, 'ì¤‘ìš” (2)':2.0, 'í•„ìˆ˜ (3)':3.0}
def w_ui(lbl, help_txt, def_idx=1): 
    return w_opts[st.sidebar.select_slider(lbl, options=list(w_opts.keys()), value=list(w_opts.keys())[def_idx], help=help_txt)]

w_cafe  = w_ui("â˜• Food & Cafe", "ì¹´í˜, ë² ì´ì»¤ë¦¬, ë””ì €íŠ¸ ì „ë¬¸ì  ë°€ë„ë¥¼ ë¶„ì„í•˜ì—¬ 'ì—¬ìœ ë¡œìš´ íœ´ì‹ê³¼ ë¯¸ì‹'ì˜ ê°€ì¹˜ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.")
w_health= w_ui("ğŸ‹ï¸ Health & Sports", "í—¬ìŠ¤ì¥, í•„ë¼í…ŒìŠ¤, ìš”ê°€ ìŠ¤íŠœë””ì˜¤ ë“± 'ìê¸°ê´€ë¦¬ì™€ ê±´ê°•í•œ ì‚¶'ì„ ìœ„í•œ ì‹œì„¤ ì ‘ê·¼ì„±ì…ë‹ˆë‹¤.")
w_conv  = w_ui("ğŸª Convenience", "í¸ì˜ì , ë¹¨ë˜ë°©, ë§ˆíŠ¸ ë“± 1ì¸ ê°€êµ¬ì˜ 'ê°€ì‚¬ íš¨ìœ¨ì„±ê³¼ ìƒí™œ í¸ì˜'ë¥¼ ì§€ì›í•˜ëŠ” ì¸í”„ë¼ì…ë‹ˆë‹¤.")
w_safe  = w_ui("ğŸ‘® Safety (ì•ˆì „)", "ìŠ¤ë§ˆíŠ¸í´, CCTV, ì§€êµ¬ëŒ€(Police) ìœ„ì¹˜ë¥¼ ì¢…í•©í•˜ì—¬ ë°¤ê¸¸ ê±±ì • ì—†ëŠ” 'ì•ˆì‹¬ ì£¼ê±° í™˜ê²½'ì„ í‰ê°€í•©ë‹ˆë‹¤.", 2)
w_med   = w_ui("ğŸ¥ Medical (ì˜ë£Œ)", "ì•½êµ­ ë° 1ì°¨ ì˜ë£Œê¸°ê´€(ë‚´ê³¼, ì¹˜ê³¼ ë“±) ë¶„í¬ë¥¼ í†µí•´ 'ë¹„ìƒì‹œ ì˜ë£Œ ëŒ€ì‘ë ¥'ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.", 2)
w_mobil = w_ui("ğŸš² Mobility (êµí†µ)", "ë”°ë¦‰ì´ ëŒ€ì—¬ì†Œ(Mobility) ë° ì§€í•˜ì² ì—­ ì ‘ê·¼ì„±ì„ ê³„ì‚°í•˜ì—¬ 'ë¼ìŠ¤íŠ¸ ë§ˆì¼ ì´ë™ì„±'ì„ ì¸¡ì •í•©ë‹ˆë‹¤.")

st.sidebar.divider()
st.sidebar.header("ğŸ” ë¶„ì„ ë²”ìœ„ ì„¤ì •")
search_radius = st.sidebar.slider("íƒìƒ‰ ë°˜ê²½", 100, 1000, 800, 100, format="%d m")
use_api = st.sidebar.checkbox("ğŸŒ ì‹¤ì‹œê°„ ê³µê³µ ë°ì´í„° ì—°ë™", value=False)

# Logic
@st.cache_data
def get_data(api_mode): return preprocess_data(use_mock=not api_mode)
@st.cache_data
def get_estates(): return generate_mock_estate_data()
@st.cache_data
def compute_index(_gdf, _rad): return calculate_seulsekwon_index(_gdf, max_dist=_rad)

if 'infra' not in st.session_state or st.session_state.get('api_mode') != use_api:
    st.session_state.infra = get_data(use_api)
    st.session_state.estates = get_estates()
    st.session_state.api_mode = use_api
    st.session_state.last_rad = None

if st.session_state.get('last_rad') != search_radius:
    with st.spinner("AI ê³µê°„ ë¶„ì„ ìˆ˜í–‰ ì¤‘..."):
        st.session_state.grid = compute_index(st.session_state.infra, search_radius)
        st.session_state.last_rad = search_radius

# Scoring (Weighted Average 100 Scale)
grid = st.session_state.grid.copy()

# Consolidate Categories
s_cafe = grid['score_cafe']
s_health = grid['score_gym'] + grid.get('score_healing', 0)
s_conv = grid['score_convenience'] + grid['score_life'] + grid.get('score_admin', 0) + grid.get('score_market', 0)
s_safe = grid['score_safety'] + grid.get('score_smart', 0)
s_med = grid['score_medical']
s_mobil = grid.get('score_mobility', 0)

numerator = (s_cafe * w_cafe + s_health * w_health + s_conv * w_conv + s_safe * w_safe + s_med * w_med + s_mobil * w_mobil)
sum_weights = w_cafe + w_health + w_conv + w_safe + w_med + w_mobil
if sum_weights == 0: sum_weights = 1
# 10 is base max score. 
grid['total_score'] = (numerator / (sum_weights * 10)) * 100
grid['total_score'] = grid['total_score'].round(1)

# Estate Scoring
estates = st.session_state.estates.copy()
grid_tree = cKDTree(list(zip(grid.geometry.x, grid.geometry.y)))
_, idxs = grid_tree.query(list(zip(estates.lon, estates.lat)), k=1)
estates['score'] = grid.iloc[idxs]['total_score'].values
estates['cpi'] = estates['score'] / estates['rent_per_area']

# Visualization
col_map, col_stat = st.columns([2, 1])

with col_map:
    # Filter Recommendation
    top_cpi = estates['cpi'].quantile(0.8)
    estates['grade'] = estates['cpi'].apply(lambda x: 'ğŸ’ ê°€ì„±ë¹„ ìµœìƒ' if x >= top_cpi else 'ì¼ë°˜')
    
    m = folium.Map([37.4842, 126.9297], zoom_start=15, tiles='cartodbpositron')
    
    # Heatmap (Fix applied)
    grid_copy = grid[grid['total_score']>0].copy()
    grid_copy['lat'] = grid_copy.geometry.y
    grid_copy['lon'] = grid_copy.geometry.x
    hm_data = grid_copy[['lat','lon','total_score']].values.tolist()
    HeatMap(hm_data, radius=15, blur=20, min_opacity=0.3).add_to(m)
    
    # Layers
    fgs = {
        'Safety': folium.FeatureGroup(name='Safety & Smart'),
        'Medical': folium.FeatureGroup(name='Medical'),
        'Life': folium.FeatureGroup(name='Convenience & Life'),
        'Mobility': folium.FeatureGroup(name='Mobility'),
        'Cafe': folium.FeatureGroup(name='Cafe'),
        'Health': folium.FeatureGroup(name='Health')
    }
    
    type_map = {
        'safety': 'Safety', 'smart': 'Safety', 
        'medical': 'Medical', 
        'convenience': 'Life', 'life': 'Life', 'admin': 'Life', 'market': 'Life',
        'mobility': 'Mobility',
        'cafe': 'Cafe',
        'gym': 'Health', 'healing': 'Health'
    }
    
    for r in st.session_state.infra.itertuples():
        t = getattr(r, 'type', 'other')
        if t in type_map:
            fg = fgs[type_map[t]]
            folium.CircleMarker(
                [r.geometry.y, r.geometry.x], radius=3, color='blue', fill=True,
                popup=f"{r.name} ({t})"
            ).add_to(fg)
            
    for fg in fgs.values(): fg.add_to(m)
    
    # Estates
    for _, e in estates.iterrows():
        if e['grade'] == 'ğŸ’ ê°€ì„±ë¹„ ìµœìƒ':
            folium.Marker(
                [e['lat'], e['lon']], 
                popup=f"<b>{e['name']}</b><br>ì¢…í•©ì ìˆ˜: {e['score']:.1f}ì <br>í‰ë‹¹: {e['rent_per_area']:.1f}ë§Œ",
                icon=folium.Icon(color='darkblue', icon='star', prefix='fa')
            ).add_to(m)
            
    folium.LayerControl().add_to(m)
    st_folium(m, height=600)

with col_stat:
    st.subheader("ğŸ“Š ì§€ì—­ ë¶„ì„ ë¦¬í¬íŠ¸")
    
    max_area_score = grid['total_score'].max()
    avg_area_score = grid[grid['total_score']>0]['total_score'].mean()
    
    m1, m2 = st.columns(2)
    m1.metric("ì§€ì—­ ìµœê³  ì ìˆ˜ (Max)", f"{max_area_score:.0f}ì ", "Premium")
    m2.metric("í‰ê·  ì£¼ê±° ê°€ì¹˜", f"{avg_area_score:.0f}ì ")
    
    st.divider()
    
    bst = estates.nlargest(3, 'cpi')
    st.markdown("#### ğŸ† Top 3 ê°€ì„±ë¹„ ë§¤ë¬¼")
    for _, r in bst.iterrows():
        st.success(f"**{r['name']}**\n- ì¢…í•© ì ìˆ˜: **{r['score']:.1f}ì ** / 100ì \n- í‰ë‹¹ ì›”ì„¸: **{r['rent_per_area']:.1f}ë§Œ ì›**")
        
    fig = px.scatter(estates, x='rent_per_area', y='score', color='grade', 
                     hover_data=['name', 'cpi'],
                     labels={'rent_per_area':'í‰ë‹¹ ì›”ì„¸ (3.3ã¡)', 'score':'í”„ë¦¬ë¯¸ì—„ ìŠ¬ì„¸ê¶Œ ì§€ìˆ˜ (100ë§Œì )'},
                     title="ê°€ê²© ëŒ€ë¹„ ê°€ì¹˜ (Value Analysis)")
    st.plotly_chart(fig, use_container_width=True)
    
    st.caption(f"Data Source: ì„œìš¸ ì—´ë¦°ë°ì´í„° ê´‘ì¥ (API Key: {API_KEY[:5]}***), êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€")
